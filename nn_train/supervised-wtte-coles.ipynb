{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "libgomp: Invalid value for environment variable OMP_NUM_THREADS\n",
      "\n",
      "libgomp: Invalid value for environment variable OMP_NUM_THREADS\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchmetrics\n",
    "import logging\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from wtte_lib.wtte_data_preprocessing import data_pipeline\n",
    "from ptls.nn import TrxEncoder, RnnSeqEncoder, Head, L2NormEncoder\n",
    "from ptls.data_load.utils import collate_feature_dict\n",
    "from ptls.data_load.datasets import MemoryMapDataset, AugmentationDataset\n",
    "from ptls.data_load.padded_batch import PaddedBatch\n",
    "from ptls.data_load.iterable_processing import SeqLenFilter\n",
    "from ptls.preprocessing import PandasDataPreprocessor\n",
    "from ptls.frames import PtlsDataModule\n",
    "from ptls.frames.coles import CoLESModule, ColesDataset\n",
    "from ptls.frames.coles.losses import SoftmaxLoss\n",
    "from ptls.frames.coles.metric import BatchRecallTopK\n",
    "from ptls.frames.coles.split_strategy import SampleSlices\n",
    "from ptls.frames.inference_module import InferenceModule\n",
    "from ptls.data_load.augmentations import RandomSlice, DropoutTrx\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = pd.read_csv('../data/transactions.csv')\n",
    "clients_df = pd.read_csv('../data/clients.csv')\n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "reports_df = pd.read_csv('../data/report_dates.csv')\n",
    "transactions_df['transaction_dttm'] = pd.to_datetime(transactions_df.transaction_dttm)\n",
    "transactions_df['transaction_dttm'] = pd.to_datetime(transactions_df['transaction_dttm'], unit='s').astype('int') // 10**9\n",
    "transactions_df['mcc_code'] += 1 \n",
    "transactions_df['ones'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep_aggregation_dict = {'ones': 'sum', 'mcc_code': 'max', 'transaction_amt': 'mean', 'currency_rk': 'max'}\n",
    "train_data = []\n",
    "transactions_df_ = transactions_df.merge(clients_df[['user_id', 'report']])\n",
    "for report in reports_df.report.values:\n",
    "    data_ = transactions_df_[transactions_df_['report']==report].copy().reset_index()\n",
    "    df_ = data_pipeline(data_, id_col='user_id', infer_seq_endtime=False, abs_time_col='transaction_dttm', column_names=[\"ones\", 'mcc_code', 'transaction_amt', 'currency_rk'], timestep_aggregation_dict=timestep_aggregation_dict)\n",
    "    train_data.append(df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_data:\n",
    "    data[0][:,-1,:] = np.array([-1, -1, -1, -1])\n",
    "data_lst = []\n",
    "for data in train_data:\n",
    "    x_ = np.nan_to_num(data[0], 0).copy()\n",
    "    x_lst = [pd.DataFrame(x_[i]) for i in range(len(x_))]\n",
    "    for df in x_lst:\n",
    "        df['target'] = df[2].map(lambda x: 0 if x else None)\n",
    "        target = df.target.values\n",
    "        indices = np.where(~np.isnan(target))[0]\n",
    "        indices[-1]+=1\n",
    "        idx = 0\n",
    "        for i, tgt in enumerate(target):\n",
    "            if np.isnan(tgt):\n",
    "                target[i] = indices[idx] - i\n",
    "            else:\n",
    "                idx+=1\n",
    "        df['target'] = target\n",
    "        df.loc[df.index[-1]] = [0, 0, 0, 0, 1]\n",
    "    for i in range(len(x_lst)):\n",
    "        x_lst[i]['user_id'] = [data[2][i]]*x_lst[i].shape[0]\n",
    "    data_lst.append(pd.concat(x_lst, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat(data_lst, axis=0)\n",
    "dataset = dataset.rename(columns={0: 'ones', 1: 'mcc_code', 2: 'transaction_amt', 3: 'currency_rk'})\n",
    "dataset['trx_dt'] = dataset.groupby('user_id').cumcount()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptls.preprocessing import PandasDataPreprocessor\n",
    "\n",
    "preprocessor = PandasDataPreprocessor(\n",
    "    col_id='user_id',\n",
    "    col_event_time='trx_dt',\n",
    "    event_time_transformation='none',\n",
    "    cols_category=['mcc_code', 'currency_rk'],\n",
    "    cols_numerical=['transaction_amt', 'ones'],\n",
    "    return_records=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataset = preprocessor.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tr_dataset).drop('target', axis=1).merge(train_df[['user_id', 'target', 'time']], on='user_id')\n",
    "test_ids = pd.read_csv('../data/test_ids.csv')\n",
    "df_train, df_test = df.loc[~df['user_id'].isin(test_ids['user_id'])], df.loc[df['user_id'].isin(test_ids['user_id'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trx_encoder_params = dict(\n",
    "    embeddings_noise=0.003,\n",
    "    numeric_values={'transaction_amt': 'identity',\n",
    "                    'ones': 'identity',\n",
    "                   },\n",
    "    embeddings={\n",
    "        'currency_rk': {'in': 5, 'out': 4},\n",
    "        'mcc_code': {'in': 333, 'out': 8},\n",
    "    },\n",
    ")\n",
    "\n",
    "seq_encoder = RnnSeqEncoder(\n",
    "    trx_encoder=TrxEncoder(**trx_encoder_params),\n",
    "    hidden_size=800,\n",
    "    type='gru',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceToTarget(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        seq_encoder: torch.nn.Module,\n",
    "        head: torch.nn.Module=None,\n",
    "        head_time: torch.nn.Module=None,\n",
    "        loss: torch.nn.Module=None,\n",
    "        metric_list: torchmetrics.Metric=None,\n",
    "        optimizer_partial=None,\n",
    "        lr_scheduler_partial=None,\n",
    "        pretrained_lr=None,\n",
    "        train_update_n_steps=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters(ignore=[\n",
    "            'seq_encoder', 'head', 'head_time', 'loss',\n",
    "            'metric_list', 'optimizer_partial', 'lr_scheduler_partial'\n",
    "        ])\n",
    "        self.seq_encoder = seq_encoder\n",
    "        self.head = head\n",
    "        self.head_time = head_time\n",
    "        self.loss = loss\n",
    "\n",
    "        if type(metric_list) is dict or type(metric_list) is DictConfig:\n",
    "            metric_list = [(k, v) for k, v in metric_list.items()]\n",
    "        else:\n",
    "            if type(metric_list) is not list:\n",
    "                metric_list = [metric_list]\n",
    "            metric_list = [(m.__class__.__name__, m) for m in metric_list]\n",
    "\n",
    "        self.train_metrics = torch.nn.ModuleDict([(name, deepcopy(mc)) for name, mc in metric_list])\n",
    "        self.valid_metrics = torch.nn.ModuleDict([(name, deepcopy(mc)) for name, mc in metric_list])\n",
    "\n",
    "        self.optimizer_partial = optimizer_partial\n",
    "        self.lr_scheduler_partial = lr_scheduler_partial\n",
    "        \n",
    "    def forward(self, x):\n",
    "        add_features = None\n",
    "        \n",
    "        if isinstance(x, tuple):\n",
    "            x, add_features = x\n",
    "\n",
    "        x = self.seq_encoder(x)\n",
    "        \n",
    "        if self.head is not None:\n",
    "            y_h = self.head(x)\n",
    "        else:\n",
    "            y_h = x\n",
    "            \n",
    "        t_h = self.head_time(x)\n",
    "        \n",
    "        return y_h, t_h\n",
    "\n",
    "    def training_step(self, batch, _):\n",
    "        x, y, t = batch\n",
    "        y_h, t_h = self(x)\n",
    "\n",
    "        loss = self.loss(y_h, y)\n",
    "        self.log('loss/train_loss', loss)\n",
    "        for name, mf in self.train_metrics.items():\n",
    "            mf(y_h, y)\n",
    "            \n",
    "        loss_t = (t_h - t / 100.0).pow(2).mean()\n",
    "        self.log('loss/loss_time', loss_t)\n",
    "        return loss + 0.1 * loss_t\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        for name, mf in self.train_metrics.items():\n",
    "            self.log(f'{name}/train', mf.compute(), prog_bar=False)\n",
    "        for name, mf in self.train_metrics.items():\n",
    "            mf.reset()\n",
    "\n",
    "    def validation_step(self, batch, _):\n",
    "        x, y, t = batch\n",
    "        y_h, t_h = self(x)\n",
    "        self.log('loss/valid', self.loss(y_h, y))\n",
    "        for name, mf in self.valid_metrics.items():\n",
    "            mf(y_h, y)\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        for name, mf in self.valid_metrics.items():\n",
    "            self.log(f'{name}/valid', mf.compute(), prog_bar=True)\n",
    "        for name, mf in self.valid_metrics.items():\n",
    "            mf.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.hparams.pretrained_lr is not None:\n",
    "            if self.hparams.pretrained_lr == 'freeze':\n",
    "                for p in self.seq_encoder.parameters():\n",
    "                    p.requires_grad = False\n",
    "                parameters = self.parameters()\n",
    "            else:\n",
    "                parameters = [\n",
    "                    {'params': self.seq_encoder.parameters(), 'lr': self.hparams.pretrained_lr},\n",
    "                    {'params': self.head.parameters()},  # use predefined lr from `self.optimizer_partial`\n",
    "                ]\n",
    "        else:\n",
    "            parameters = self.parameters()\n",
    "\n",
    "        optimizer = self.optimizer_partial(parameters)\n",
    "        scheduler = self.lr_scheduler_partial(optimizer)\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqToTargetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 target_col_name,\n",
    "                 target_dtype=None,\n",
    "                 *args, **kwargs,\n",
    "                 ):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.data = data\n",
    "        \n",
    "        self.target_col_name = target_col_name\n",
    "        if type(target_dtype) is str:\n",
    "            self.target_dtype = getattr(torch, target_dtype)\n",
    "        else:\n",
    "            self.target_dtype = target_dtype\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        feature_arrays = self.data[item]\n",
    "        return feature_arrays\n",
    "\n",
    "    def __iter__(self):\n",
    "        for feature_arrays in self.data:\n",
    "            yield feature_arrays\n",
    "\n",
    "    def collate_fn(self, padded_batch):\n",
    "        padded_batch = collate_feature_dict(padded_batch)\n",
    "        \n",
    "        target = padded_batch.payload[self.target_col_name]\n",
    "        time = padded_batch.payload['time']\n",
    "        del padded_batch.payload[self.target_col_name]\n",
    "        if self.target_dtype is not None:\n",
    "            target = target.to(dtype=self.target_dtype)\n",
    "\n",
    "        return padded_batch, target, time\n",
    "\n",
    "\n",
    "class SeqToTargetIterableDataset(SeqToTargetDataset, torch.utils.data.IterableDataset):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, dl, device='cuda:0'):\n",
    "    logits = []\n",
    "    model.to(device)\n",
    "    softmax = torch.nn.Softmax(dim=0) \n",
    "    for batch in tqdm.tqdm(dl, position=0, leave=True):\n",
    "        with torch.no_grad():\n",
    "            x, _, _ = batch\n",
    "            y_h, t_h = model(x.to(device))\n",
    "            logits.extend([y_h.cpu()])\n",
    "        \n",
    "    logits = softmax(torch.vstack(logits)[:, 1]).cpu()\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "models = []\n",
    "predictions_5folds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | seq_encoder   | RnnSeqEncoder | 2.0 M \n",
      "1 | head          | Sequential    | 411 K \n",
      "2 | head_time     | Sequential    | 801   \n",
      "3 | loss          | NLLLoss       | 0     \n",
      "4 | train_metrics | ModuleDict    | 0     \n",
      "5 | valid_metrics | ModuleDict    | 0     \n",
      "------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.495     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e026fefc15cd4cc8bd24878cde7e0a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32507b403004a398708467b4993499e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "485d0f867dae481a9783a7c9201635d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 17.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "AUROC; 5th fold: 0.6177440894494072\n",
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | seq_encoder   | RnnSeqEncoder | 2.0 M \n",
      "1 | head          | Sequential    | 411 K \n",
      "2 | head_time     | Sequential    | 801   \n",
      "3 | loss          | NLLLoss       | 0     \n",
      "4 | train_metrics | ModuleDict    | 0     \n",
      "5 | valid_metrics | ModuleDict    | 0     \n",
      "------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.495     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ccdb9f96a0461abbd78c0cd6dd66c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3103d2d174194218a6399e993a080548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ebc5c354ac4bf6ac2f0bd39216a7fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 14.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "AUROC; 5th fold: 0.5939432187259301\n",
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | seq_encoder   | RnnSeqEncoder | 2.0 M \n",
      "1 | head          | Sequential    | 411 K \n",
      "2 | head_time     | Sequential    | 801   \n",
      "3 | loss          | NLLLoss       | 0     \n",
      "4 | train_metrics | ModuleDict    | 0     \n",
      "5 | valid_metrics | ModuleDict    | 0     \n",
      "------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.495     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a7830538f14a95bb9b59195bdf2f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "345ec9e475784143b58cee2031f70e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37af4a0de23a4e69a91085c7e28d1c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 14.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "AUROC; 5th fold: 0.6366426470065416\n",
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | seq_encoder   | RnnSeqEncoder | 2.0 M \n",
      "1 | head          | Sequential    | 411 K \n",
      "2 | head_time     | Sequential    | 801   \n",
      "3 | loss          | NLLLoss       | 0     \n",
      "4 | train_metrics | ModuleDict    | 0     \n",
      "5 | valid_metrics | ModuleDict    | 0     \n",
      "------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.495     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da70af7b6994fb3ae76ccf11172d9e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db07d0edb0b4b739ab4f6308420f282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4da3b8843e64b759696afdf8cf1995d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 14.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "AUROC; 5th fold: 0.5701167801360447\n",
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | seq_encoder   | RnnSeqEncoder | 2.0 M \n",
      "1 | head          | Sequential    | 411 K \n",
      "2 | head_time     | Sequential    | 801   \n",
      "3 | loss          | NLLLoss       | 0     \n",
      "4 | train_metrics | ModuleDict    | 0     \n",
      "5 | valid_metrics | ModuleDict    | 0     \n",
      "------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.495     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "010ad65de56e4169a0b73c81e87e89eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec77a6ef8eca42cc88255587776b0233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7383e8227f544c21a9f60c673abae73b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 14.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "AUROC; 5th fold: 0.5716389017270257\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "for i, (train_index, test_index) in enumerate(skf.split(df_train.drop(columns=['target']), df_train['target'])):\n",
    "    train_, test_ = df_train.iloc[train_index], df_train.iloc[test_index]\n",
    "    \n",
    "    dataset_train = train_.to_dict(orient='records')\n",
    "    dataset_test = test_.to_dict(orient='records')\n",
    "    \n",
    "    sup_dataset = PtlsDataModule(\n",
    "        train_data=SeqToTargetDataset(\n",
    "            AugmentationDataset(\n",
    "                dataset_train,\n",
    "                f_augmentations=[\n",
    "                    DropoutTrx(0.1),\n",
    "                ],\n",
    "            ),\n",
    "            target_col_name='target',\n",
    "            target_dtype=torch.long,\n",
    "        ),\n",
    "        valid_data=SeqToTargetDataset(\n",
    "            dataset_test,\n",
    "            target_col_name='target',\n",
    "            target_dtype=torch.long,\n",
    "        ),\n",
    "        train_batch_size=256,\n",
    "        train_num_workers=8,\n",
    "        train_drop_last=True,\n",
    "\n",
    "        valid_batch_size=256,\n",
    "        valid_num_workers=8,\n",
    "        valid_drop_last=True\n",
    "    )\n",
    "    \n",
    "    seq_encoder.load_state_dict(torch.load('../models/coles-wtte-model1.pt'))\n",
    "\n",
    "    sup_module = SequenceToTarget(\n",
    "        seq_encoder=seq_encoder,\n",
    "        head=torch.nn.Sequential(\n",
    "            torch.nn.Linear(seq_encoder.embedding_size, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            torch.nn.Linear(512, 2),\n",
    "            torch.nn.LogSoftmax(dim=1),\n",
    "        ),\n",
    "        head_time=torch.nn.Sequential(\n",
    "            torch.nn.Linear(seq_encoder.embedding_size, 1),\n",
    "        ),\n",
    "        loss=torch.nn.NLLLoss(),\n",
    "        metric_list=torchmetrics.AUROC(num_classes=2),\n",
    "        optimizer_partial=partial(torch.optim.AdamW, lr=1e-3, weight_decay=0.0),\n",
    "        lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=1, gamma=0.2),\n",
    "    )\n",
    "    \n",
    "    \n",
    "    trainer = pl.Trainer(\n",
    "        logger=TensorBoardLogger('lightning_logs', name=f'CoLES-WTTE-supervised_{i}'),\n",
    "        max_epochs=1,\n",
    "        gpus=1 if torch.cuda.is_available() else 0,\n",
    "        enable_progress_bar=True,\n",
    "        gradient_clip_algorithm='norm',\n",
    "        gradient_clip_val=0.18\n",
    "    )\n",
    "    \n",
    "    trainer.fit(sup_module, sup_dataset)\n",
    "    \n",
    "    torch.save(sup_module.state_dict(), f\"../models/sup_modules-wtte-kfold.{i}.pt\")\n",
    "    \n",
    "    predictions_test = test_[[\"user_id\"]].copy()\n",
    "    \n",
    "    dataset = SeqToTargetDataset(\n",
    "        data=dataset_test,\n",
    "        target_col_name='target',\n",
    "    )\n",
    "\n",
    "    dl = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        collate_fn=dataset.collate_fn,\n",
    "        shuffle=False,\n",
    "        batch_size=512,\n",
    "        num_workers=4,\n",
    "    )\n",
    "    \n",
    "    predictions_test[\"sp\"] = inference(sup_module, dl)\n",
    "    \n",
    "    predictions_5folds.append(predictions_test)\n",
    "    \n",
    "    print(12*\"-\")\n",
    "    print(\"AUROC; 5th fold:\", roc_auc_score(test_[\"target\"].values, predictions_test[\"sp\"]))\n",
    "    print(12*\"-\")\n",
    "    \n",
    "    models.append(deepcopy(sup_module))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "AUROC; 5th fold: 0.5986431096538156\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "predictions_5folds = pd.concat(predictions_5folds, axis=0)\n",
    "temp = predictions_5folds.merge(train_df[[\"user_id\", \"target\"]], on=\"user_id\")\n",
    "print(12*\"-\")\n",
    "print(\"AUROC; 5th fold:\", roc_auc_score(temp[\"target\"].values, temp[\"sp\"].values))\n",
    "print(12*\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 18.27it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.67it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.68it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.98it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "AUROC; 5th fold: 0.6531598405182077\n",
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_test = df_test.copy()\n",
    "dataset_test[[\"target\", \"time\"]] = None\n",
    "dataset_test = dataset_test.to_dict(orient='records')\n",
    "\n",
    "dataset = SeqToTargetDataset(\n",
    "    data=dataset_test,\n",
    "    target_col_name='target',\n",
    ")\n",
    "\n",
    "dl = torch.utils.data.DataLoader(\n",
    "    dataset=dataset,\n",
    "    collate_fn=dataset.collate_fn,\n",
    "    shuffle=False,\n",
    "    batch_size=512,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "predictions_test = df_test[[\"user_id\"]].copy()\n",
    "\n",
    "for i in range(5):\n",
    "    predictions_test[f\"sp_{i}\"] = inference(models[i], dl)\n",
    "predictions_test[\"sp\"] = predictions_test.iloc[:, 1:].mean(axis=1)\n",
    "predictions_test\n",
    "print(12*\"-\")\n",
    "print(\"AUROC; 5th fold:\", roc_auc_score(df_test[\"target\"].values, predictions_test[\"sp\"].values))\n",
    "print(12*\"-\")\n",
    "train_test_predictions = pd.concat([predictions_5folds, predictions_test[[\"user_id\", \"sp\"]]], axis=0)\n",
    "#train_test_predictions.to_csv(\"sp-preds_train-test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submit = pd.read_csv(\"../data/sample_submit_naive.csv\")\n",
    "sbmt_df = pd.DataFrame(tr_dataset).drop('target', axis=1).merge(sample_submit[['user_id']], on='user_id')\n",
    "sbmt_df[[\"target\", \"time\"]] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | seq_encoder   | RnnSeqEncoder | 2.0 M \n",
      "1 | head          | Sequential    | 411 K \n",
      "2 | head_time     | Sequential    | 801   \n",
      "3 | loss          | NLLLoss       | 0     \n",
      "4 | train_metrics | ModuleDict    | 0     \n",
      "5 | valid_metrics | ModuleDict    | 0     \n",
      "------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.495     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08328de6cb3b483dbef121670739def6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32dacb4710aa4199a75acf6f509da147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3be0c9b15724b82941413d2b41de3a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "AUROC; 5th fold: 0.6113231628862609\n",
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | seq_encoder   | RnnSeqEncoder | 2.0 M \n",
      "1 | head          | Sequential    | 411 K \n",
      "2 | head_time     | Sequential    | 801   \n",
      "3 | loss          | NLLLoss       | 0     \n",
      "4 | train_metrics | ModuleDict    | 0     \n",
      "5 | valid_metrics | ModuleDict    | 0     \n",
      "------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.495     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e9fa9b99c0a49749f17c1b231ba2fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9afc2bfb0647d0945e0390f2dc0f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8aa9d5205bc41cdad4df2c6c57db371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 16.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "AUROC; 5th fold: 0.6335909240316668\n",
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | seq_encoder   | RnnSeqEncoder | 2.0 M \n",
      "1 | head          | Sequential    | 411 K \n",
      "2 | head_time     | Sequential    | 801   \n",
      "3 | loss          | NLLLoss       | 0     \n",
      "4 | train_metrics | ModuleDict    | 0     \n",
      "5 | valid_metrics | ModuleDict    | 0     \n",
      "------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.495     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b3e5d2687e47f19e0f6c93082aa37b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5d176d30ff46b99f33a9dddb5c14ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "543e63a7a4364db3954cdb4765fb3ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 14.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "AUROC; 5th fold: 0.6286711915061187\n",
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | seq_encoder   | RnnSeqEncoder | 2.0 M \n",
      "1 | head          | Sequential    | 411 K \n",
      "2 | head_time     | Sequential    | 801   \n",
      "3 | loss          | NLLLoss       | 0     \n",
      "4 | train_metrics | ModuleDict    | 0     \n",
      "5 | valid_metrics | ModuleDict    | 0     \n",
      "------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.495     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd60333304b947d19054bee7d7e09ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c26bd3f9332444d8bccc24393d275080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df228afba5e4301a9dccd5cd9cfad03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 13.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "AUROC; 5th fold: 0.5703367615359322\n",
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | seq_encoder   | RnnSeqEncoder | 2.0 M \n",
      "1 | head          | Sequential    | 411 K \n",
      "2 | head_time     | Sequential    | 801   \n",
      "3 | loss          | NLLLoss       | 0     \n",
      "4 | train_metrics | ModuleDict    | 0     \n",
      "5 | valid_metrics | ModuleDict    | 0     \n",
      "------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.495     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73b66ea3ed945ac9bfed95e1a72fee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96889c464cb44befbb824846434e19c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889c169e73cb45acb8904f34cac02c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 13.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "AUROC; 5th fold: 0.5692022074710335\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "sbmt_models = []\n",
    "for i, (train_index, test_index) in enumerate(skf.split(df.drop(columns=['target']), df[\"target\"])):\n",
    "    train_, test_ = df.iloc[train_index], df.iloc[test_index]\n",
    "    \n",
    "    dataset_train = train_.to_dict(orient='records')\n",
    "    dataset_test = test_.to_dict(orient='records')\n",
    "    \n",
    "    sup_dataset = PtlsDataModule(\n",
    "        train_data=SeqToTargetDataset(\n",
    "            AugmentationDataset(\n",
    "                dataset_train,\n",
    "                f_augmentations=[\n",
    "                    DropoutTrx(0.1),\n",
    "                ],\n",
    "            ),\n",
    "            target_col_name='target',\n",
    "            target_dtype=torch.long,\n",
    "        ),\n",
    "        valid_data=SeqToTargetDataset(\n",
    "            dataset_test,\n",
    "            target_col_name='target',\n",
    "            target_dtype=torch.long,\n",
    "        ),\n",
    "        train_batch_size=256,\n",
    "        train_num_workers=8,\n",
    "        train_drop_last=True,\n",
    "\n",
    "        valid_batch_size=256,\n",
    "        valid_num_workers=8,\n",
    "        valid_drop_last=True\n",
    "    )\n",
    "    \n",
    "    seq_encoder.load_state_dict(torch.load('../models/coles-wtte-model1.pt'))\n",
    "\n",
    "    sup_module = SequenceToTarget(\n",
    "        seq_encoder=seq_encoder,\n",
    "        head=torch.nn.Sequential(\n",
    "            torch.nn.Linear(seq_encoder.embedding_size, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            torch.nn.Linear(512, 2),\n",
    "            torch.nn.LogSoftmax(dim=1),\n",
    "        ),\n",
    "        head_time=torch.nn.Sequential(\n",
    "            torch.nn.Linear(seq_encoder.embedding_size, 1),\n",
    "        ),\n",
    "        loss=torch.nn.NLLLoss(),\n",
    "        metric_list=torchmetrics.AUROC(num_classes=2),\n",
    "        optimizer_partial=partial(torch.optim.AdamW, lr=4e-4, weight_decay=0.0),\n",
    "        lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=1, gamma=0.2),\n",
    "    )\n",
    "    \n",
    "    trainer = pl.Trainer(\n",
    "        logger=TensorBoardLogger('lightning_logs', name=f'CoLES-WTTE-supervised-sbmt_{i}'),\n",
    "        max_epochs=1,\n",
    "        gpus=1 if torch.cuda.is_available() else 0,\n",
    "        enable_progress_bar=True,\n",
    "        gradient_clip_algorithm='norm',\n",
    "        gradient_clip_val=0.2\n",
    "    )\n",
    "    \n",
    "    trainer.fit(sup_module, sup_dataset)\n",
    "    \n",
    "    #torch.save(sup_module.state_dict(), f\"model/sup_modules-kfold/sbmt-model-0.{i}.pt\")\n",
    "    \n",
    "    dataset = SeqToTargetDataset(\n",
    "        data=dataset_test,\n",
    "        target_col_name='target',\n",
    "    )\n",
    "\n",
    "    dl = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        collate_fn=dataset.collate_fn,\n",
    "        shuffle=False,\n",
    "        batch_size=512,\n",
    "        num_workers=4,\n",
    "    )\n",
    "    \n",
    "    predictions_test = inference(sup_module, dl)\n",
    "    \n",
    "    print(12*\"-\")\n",
    "    print(\"AUROC; 5th fold:\", roc_auc_score(test_[\"target\"].values, predictions_test))\n",
    "    print(12*\"-\")\n",
    "    \n",
    "    sbmt_models.append(deepcopy(sup_module))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:02<00:00, 22.48it/s]\n",
      "100%|██████████| 63/63 [00:02<00:00, 23.35it/s]\n",
      "100%|██████████| 63/63 [00:02<00:00, 24.04it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 19.04it/s]\n",
      "100%|██████████| 63/63 [00:02<00:00, 22.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>sp_0</th>\n",
       "      <th>sp_1</th>\n",
       "      <th>sp_2</th>\n",
       "      <th>sp_3</th>\n",
       "      <th>sp_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31995</th>\n",
       "      <td>561362</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31996</th>\n",
       "      <td>561419</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31997</th>\n",
       "      <td>561895</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31998</th>\n",
       "      <td>561908</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31999</th>\n",
       "      <td>562205</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id      sp_0      sp_1      sp_2      sp_3      sp_4\n",
       "0            9  0.000038  0.000030  0.000047  0.000057  0.000043\n",
       "1           61  0.000033  0.000046  0.000033  0.000033  0.000038\n",
       "2           62  0.000032  0.000048  0.000040  0.000038  0.000041\n",
       "3           80  0.000014  0.000012  0.000015  0.000014  0.000023\n",
       "4           88  0.000036  0.000043  0.000050  0.000039  0.000043\n",
       "...        ...       ...       ...       ...       ...       ...\n",
       "31995   561362  0.000037  0.000029  0.000036  0.000030  0.000024\n",
       "31996   561419  0.000029  0.000027  0.000038  0.000051  0.000031\n",
       "31997   561895  0.000018  0.000024  0.000018  0.000017  0.000031\n",
       "31998   561908  0.000042  0.000045  0.000034  0.000039  0.000034\n",
       "31999   562205  0.000014  0.000023  0.000018  0.000026  0.000022\n",
       "\n",
       "[32000 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sbmt = sbmt_df.copy()\n",
    "dataset_sbmt[[\"target\", \"time\"]] = None\n",
    "dataset_sbmt = dataset_sbmt.to_dict(orient='records')\n",
    "\n",
    "dataset = SeqToTargetDataset(\n",
    "    data=dataset_sbmt,\n",
    "    target_col_name='target',\n",
    ")\n",
    "\n",
    "dl = torch.utils.data.DataLoader(\n",
    "    dataset=dataset,\n",
    "    collate_fn=dataset.collate_fn,\n",
    "    shuffle=False,\n",
    "    batch_size=512,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "predictions_sbmt = sbmt_df[[\"user_id\"]].copy()\n",
    "\n",
    "for i in range(5):\n",
    "    predictions_sbmt[f\"sp_{i}\"] = inference(sbmt_models[i], dl)\n",
    "\n",
    "predictions_sbmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>sp_0</th>\n",
       "      <th>sp_1</th>\n",
       "      <th>sp_2</th>\n",
       "      <th>sp_3</th>\n",
       "      <th>sp_4</th>\n",
       "      <th>sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31995</th>\n",
       "      <td>561362</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31996</th>\n",
       "      <td>561419</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31997</th>\n",
       "      <td>561895</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31998</th>\n",
       "      <td>561908</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31999</th>\n",
       "      <td>562205</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id      sp_0      sp_1      sp_2      sp_3      sp_4        sp\n",
       "0            9  0.000038  0.000030  0.000047  0.000057  0.000043  0.000043\n",
       "1           61  0.000033  0.000046  0.000033  0.000033  0.000038  0.000037\n",
       "2           62  0.000032  0.000048  0.000040  0.000038  0.000041  0.000040\n",
       "3           80  0.000014  0.000012  0.000015  0.000014  0.000023  0.000016\n",
       "4           88  0.000036  0.000043  0.000050  0.000039  0.000043  0.000042\n",
       "...        ...       ...       ...       ...       ...       ...       ...\n",
       "31995   561362  0.000037  0.000029  0.000036  0.000030  0.000024  0.000031\n",
       "31996   561419  0.000029  0.000027  0.000038  0.000051  0.000031  0.000035\n",
       "31997   561895  0.000018  0.000024  0.000018  0.000017  0.000031  0.000022\n",
       "31998   561908  0.000042  0.000045  0.000034  0.000039  0.000034  0.000039\n",
       "31999   562205  0.000014  0.000023  0.000018  0.000026  0.000022  0.000020\n",
       "\n",
       "[32000 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_sbmt[\"sp\"] = predictions_sbmt.iloc[:, 1:].mean(axis=1)\n",
    "predictions_sbmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction = pd.concat([predictions_sbmt[[\"user_id\", \"sp\"]], train_test_predictions])\n",
    "final_prediction.to_csv(\"../predicts/sup-wtte-preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ESF",
   "language": "python",
   "name": "esf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
