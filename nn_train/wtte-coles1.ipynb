{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "076bdc2f-79d9-4daf-b439-7c2546e5eb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from wtte_lib.wtte_data_preprocessing import data_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8477797-9742-4bf3-b7d3-14befe188020",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = pd.read_csv('../data/transactions.csv')\n",
    "clients_df = pd.read_csv('../data/clients.csv')\n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "reports_df = pd.read_csv('../data/report_dates.csv')\n",
    "transactions_df['transaction_dttm'] = pd.to_datetime(transactions_df.transaction_dttm)\n",
    "transactions_df['transaction_dttm'] = pd.to_datetime(transactions_df['transaction_dttm'], unit='s').astype('int') // 10**9\n",
    "transactions_df['mcc_code'] += 1 \n",
    "transactions_df['ones'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfa3e17b-fe2f-48b1-b184-3bd9bbc90d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep_aggregation_dict = {'ones': 'sum', 'mcc_code': 'max', 'transaction_amt': 'mean', 'currency_rk': 'max'}\n",
    "train_data = []\n",
    "transactions_df_ = transactions_df.merge(clients_df[['user_id', 'report']])\n",
    "for report in reports_df.report.values:\n",
    "    data_ = transactions_df_[transactions_df_['report']==report].copy().reset_index()\n",
    "    df_ = data_pipeline(data_, id_col='user_id', infer_seq_endtime=False, abs_time_col='transaction_dttm', column_names=[\"ones\", 'mcc_code', 'transaction_amt', 'currency_rk'], timestep_aggregation_dict=timestep_aggregation_dict)\n",
    "    train_data.append(df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a49c278-ee2a-4ff4-b6c6-77c1ad30b689",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_data:\n",
    "    data[0][:,-1,:] = np.array([-1, -1, -1, -1])\n",
    "data_lst = []\n",
    "for data in train_data:\n",
    "    x_ = np.nan_to_num(data[0], 0).copy()\n",
    "    x_lst = [pd.DataFrame(x_[i]) for i in range(len(x_))]\n",
    "    for df in x_lst:\n",
    "        df['target'] = df[2].map(lambda x: 0 if x else None)\n",
    "        target = df.target.values\n",
    "        indices = np.where(~np.isnan(target))[0]\n",
    "        indices[-1]+=1\n",
    "        idx = 0\n",
    "        for i, tgt in enumerate(target):\n",
    "            if np.isnan(tgt):\n",
    "                target[i] = indices[idx] - i\n",
    "            else:\n",
    "                idx+=1\n",
    "        df['target'] = target\n",
    "        df.loc[df.index[-1]] = [0, 0, 0, 0, 1]\n",
    "    for i in range(len(x_lst)):\n",
    "        x_lst[i]['user_id'] = [data[2][i]]*x_lst[i].shape[0]\n",
    "    data_lst.append(pd.concat(x_lst, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b15b96ce-8abe-4b8f-a579-f357c8fbb14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat(data_lst, axis=0)\n",
    "dataset = dataset.rename(columns={0: 'ones', 1: 'mcc_code', 2: 'transaction_amt', 3: 'currency_rk'})\n",
    "dataset['trx_dt'] = dataset.groupby('user_id').cumcount()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1acd7522-7a2b-415e-93d1-ece8c2898c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "libgomp: Invalid value for environment variable OMP_NUM_THREADS\n",
      "\n",
      "libgomp: Invalid value for environment variable OMP_NUM_THREADS\n"
     ]
    }
   ],
   "source": [
    "from ptls.preprocessing import PandasDataPreprocessor\n",
    "\n",
    "preprocessor = PandasDataPreprocessor(\n",
    "    col_id='user_id',\n",
    "    col_event_time='trx_dt',\n",
    "    event_time_transformation='none',\n",
    "    cols_category=['mcc_code', 'currency_rk'],\n",
    "    cols_numerical=['transaction_amt', 'ones'],\n",
    "    return_records=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8370822-17a0-4014-b6a8-d1fdc9dae4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataset = preprocessor.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2379f951-a51b-4e32-bac0-0f22a36a9bb1",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aff1c2f4-1765-4ff6-9365-1cd838a00deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from functools import partial\n",
    "from ptls.nn import TrxEncoder, RnnSeqEncoder\n",
    "from ptls.frames.coles import CoLESModule\n",
    "import lion_pytorch\n",
    "from ptls.frames.coles.losses import SoftmaxLoss\n",
    "from ptls.data_load.datasets import MemoryMapDataset\n",
    "from ptls.data_load.iterable_processing import SeqLenFilter\n",
    "from ptls.frames.coles import ColesDataset\n",
    "from ptls.frames.coles.split_strategy import SampleSlices\n",
    "from ptls.frames import PtlsDataModule\n",
    "from ptls.frames.inference_module import InferenceModule\n",
    "from ptls.data_load.utils import collate_feature_dict\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "trx_encoder_params = dict(\n",
    "    embeddings_noise=0.003,\n",
    "    numeric_values={'transaction_amt': 'identity',\n",
    "                    'ones': 'identity',\n",
    "                   },\n",
    "    embeddings={\n",
    "        'currency_rk': {'in': 5, 'out': 4},\n",
    "        'mcc_code': {'in': 333, 'out': 8},\n",
    "    },\n",
    ")\n",
    "\n",
    "train_dl = PtlsDataModule(\n",
    "    train_data=ColesDataset(\n",
    "        MemoryMapDataset(\n",
    "            data=tr_dataset,\n",
    "            i_filters=[\n",
    "                SeqLenFilter(min_seq_len=10)\n",
    "            ],\n",
    "        ),\n",
    "        splitter=SampleSlices(\n",
    "            split_count=5,\n",
    "            cnt_min=20,\n",
    "            cnt_max=150,\n",
    "        ),\n",
    "    ),\n",
    "    train_num_workers=8,\n",
    "    train_batch_size=512,\n",
    "    valid_num_workers=8,\n",
    "    valid_batch_size=512,\n",
    ")\n",
    "\n",
    "inference_dataset = MemoryMapDataset(\n",
    "    data=tr_dataset,\n",
    ")\n",
    "\n",
    "inference_dl = torch.utils.data.DataLoader(\n",
    "    dataset=inference_dataset,\n",
    "    collate_fn=collate_feature_dict,\n",
    "    shuffle=False,\n",
    "    batch_size=128,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "def get_wtte_coles_embeddings(random_seed):\n",
    "\n",
    "    seq_encoder = RnnSeqEncoder(\n",
    "        trx_encoder=TrxEncoder(**trx_encoder_params),\n",
    "        hidden_size=800,\n",
    "        type='gru',\n",
    "    )\n",
    "\n",
    "    model = CoLESModule(\n",
    "        seq_encoder=seq_encoder,\n",
    "        optimizer_partial=partial(lion_pytorch.Lion, lr=0.0001),\n",
    "        lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=5, gamma=0.9),\n",
    "        loss = SoftmaxLoss()\n",
    "    )\n",
    "    \n",
    "    trainer = pl.Trainer(\n",
    "        logger=TensorBoardLogger('lightning_logs', name=f'coles_{i}'),\n",
    "        max_epochs=1,\n",
    "        gpus=1 if torch.cuda.is_available() else 0,\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "    trainer.fit(model, train_dl)\n",
    "    torch.save(model.seq_encoder.state_dict(), f\"../models/coles-wtte-model{i}.pt\")\n",
    "    inference_module = InferenceModule(\n",
    "        model=seq_encoder,\n",
    "        pandas_output=True,\n",
    "        drop_seq_features=True,\n",
    "        model_out_name=f'emb_wtte_coles_{random_seed}')\n",
    "    \n",
    "    predict = pl.Trainer(gpus=1).predict(inference_module, inference_dl)\n",
    "    full_predict = pd.concat(predict, axis=0)\n",
    "    full_predict.to_csv(f'../embeddings/wtte_coles_{random_seed}.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a30eefdf-e0d1-4d10-8f7e-58c89d4c76c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/jovyan/.local/share/virtualenvs/ESFormers-uesovGUt/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:133: UserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\"You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logger.version = 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name               | Type            | Params\n",
      "-------------------------------------------------------\n",
      "0 | _loss              | SoftmaxLoss     | 0     \n",
      "1 | _seq_encoder       | RnnSeqEncoder   | 2.0 M \n",
      "2 | _validation_metric | BatchRecallTopK | 0     \n",
      "3 | _head              | Head            | 0     \n",
      "-------------------------------------------------------\n",
      "2.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 M     Total params\n",
      "7.848     Total estimated model params size (MB)\n",
      "/home/jovyan/.local/share/virtualenvs/ESFormers-uesovGUt/lib/python3.8/site-packages/pytorch_lightning/loops/utilities.py:92: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7516ae669d46e4b393353464b4ae1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 2\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/jovyan/.local/share/virtualenvs/ESFormers-uesovGUt/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:133: UserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\"You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name               | Type            | Params\n",
      "-------------------------------------------------------\n",
      "0 | _loss              | SoftmaxLoss     | 0     \n",
      "1 | _seq_encoder       | RnnSeqEncoder   | 2.0 M \n",
      "2 | _validation_metric | BatchRecallTopK | 0     \n",
      "3 | _head              | Head            | 0     \n",
      "-------------------------------------------------------\n",
      "2.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 M     Total params\n",
      "7.848     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logger.version = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/share/virtualenvs/ESFormers-uesovGUt/lib/python3.8/site-packages/pytorch_lightning/loops/utilities.py:92: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e86006ce064055803e2d5c70ab43b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 3\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/jovyan/.local/share/virtualenvs/ESFormers-uesovGUt/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:133: UserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\"You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name               | Type            | Params\n",
      "-------------------------------------------------------\n",
      "0 | _loss              | SoftmaxLoss     | 0     \n",
      "1 | _seq_encoder       | RnnSeqEncoder   | 2.0 M \n",
      "2 | _validation_metric | BatchRecallTopK | 0     \n",
      "3 | _head              | Head            | 0     \n",
      "-------------------------------------------------------\n",
      "2.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 M     Total params\n",
      "7.848     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logger.version = 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/share/virtualenvs/ESFormers-uesovGUt/lib/python3.8/site-packages/pytorch_lightning/loops/utilities.py:92: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78514be3ef5d4ac5a114cc00ce2ef06e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 4\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/jovyan/.local/share/virtualenvs/ESFormers-uesovGUt/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:133: UserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\"You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name               | Type            | Params\n",
      "-------------------------------------------------------\n",
      "0 | _loss              | SoftmaxLoss     | 0     \n",
      "1 | _seq_encoder       | RnnSeqEncoder   | 2.0 M \n",
      "2 | _validation_metric | BatchRecallTopK | 0     \n",
      "3 | _head              | Head            | 0     \n",
      "-------------------------------------------------------\n",
      "2.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 M     Total params\n",
      "7.848     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logger.version = 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/share/virtualenvs/ESFormers-uesovGUt/lib/python3.8/site-packages/pytorch_lightning/loops/utilities.py:92: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "441e1963b7ff4892a05167f10fa57991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 5\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/jovyan/.local/share/virtualenvs/ESFormers-uesovGUt/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:133: UserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\"You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name               | Type            | Params\n",
      "-------------------------------------------------------\n",
      "0 | _loss              | SoftmaxLoss     | 0     \n",
      "1 | _seq_encoder       | RnnSeqEncoder   | 2.0 M \n",
      "2 | _validation_metric | BatchRecallTopK | 0     \n",
      "3 | _head              | Head            | 0     \n",
      "-------------------------------------------------------\n",
      "2.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 M     Total params\n",
      "7.848     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logger.version = 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/share/virtualenvs/ESFormers-uesovGUt/lib/python3.8/site-packages/pytorch_lightning/loops/utilities.py:92: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e4d8331c354693b6f40fdec4631c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    pl.seed_everything(i)\n",
    "    get_wtte_coles_embeddings(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb391b13-1ee2-40b0-9a91-c36aa0db11fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from ptls.data_load.datasets import inference_data_loader\n",
    "seq_encoder = RnnSeqEncoder(\n",
    "        trx_encoder=TrxEncoder(**trx_encoder_params),\n",
    "        hidden_size=800,\n",
    "        type='gru',\n",
    "    )\n",
    "seq_encoder.load_state_dict(torch.load('../models/coles-wtte-model1.pt'))\n",
    "def pooling_inference(seq_encoder, dl, device='cuda:0'):\n",
    "    \n",
    "    seq_encoder.to(device)\n",
    "    X = []\n",
    "    for batch in tqdm.tqdm(dl):\n",
    "        with torch.no_grad():\n",
    "            x = seq_encoder.trx_encoder(batch.to(device)).payload\n",
    "            features_all = []\n",
    "            for i in range(0, 182, 30):\n",
    "                x_30 = x[:, i:]\n",
    "                out_max = torch.max(x_30, dim=1)[0]\n",
    "                out_min = torch.min(x_30, dim=1)[0]\n",
    "                out_mean = torch.mean(x_30, dim=1)\n",
    "                out_std = torch.std(x_30, dim=1)\n",
    "                features = torch.cat([out_max, out_min, out_mean, out_std], dim=1) \n",
    "                features_all.append(features)\n",
    "            features1 = torch.cat(features_all, dim = 1)\n",
    "            X += [features1]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96bb84a1-c821-46cd-bc05-8a15237dcff3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47it [00:09,  4.79it/s]\n"
     ]
    }
   ],
   "source": [
    "dl = inference_data_loader(tr_dataset, num_workers=0, batch_size=2048)\n",
    "df_ab = torch.vstack(pooling_inference(seq_encoder, dl)).cpu().numpy()\n",
    "df_embeds = pd.DataFrame(df_ab, columns=[f\"emb_wtte_coles_trx_{e}\" for e in range(df_ab.shape[1])])\n",
    "df_embeds['user_id'] = pd.DataFrame(tr_dataset)['user_id']\n",
    "df_embeds.to_csv('../embeddings/wtte_coles_trx.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ESF",
   "language": "python",
   "name": "esf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
