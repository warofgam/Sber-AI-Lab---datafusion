{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Позаимствовали агрегированные фичи у kdimon15. Спасибо! <br>\n",
    "https://github.com/kdimon15/data-fusion-2024-baseline/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['NUMEXPR_MAX_THREADS'] = '32'\n",
    "# os.environ['NUMEXPR_NUM_THREADS'] = '30'\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 100\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = pd.read_csv('../data/train.csv')\n",
    "\n",
    "sample = pd.read_csv('../data/sample_submit_naive.csv').drop('predict', axis=1)\n",
    "sample['target'] = -1\n",
    "\n",
    "main = pd.concat([main, sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = pd.read_csv('../data/clients.csv')\n",
    "report_dates = pd.read_csv('../data/report_dates.csv', parse_dates=['report_dt'])\n",
    "\n",
    "transactions = pd.read_csv('../data/transactions.csv', parse_dates=['transaction_dttm'])\n",
    "transactions = transactions.sort_values('transaction_dttm').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим информацию о клиенте, а также закодируем employee_count_nm\n",
    "\n",
    "main = main.merge(clients, how='left', on='user_id')\n",
    "main['employee_count_nm'] = LabelEncoder().fit_transform(main['employee_count_nm'].fillna('unknown'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_codes = transactions['mcc_code'].value_counts()\n",
    "good_codes = good_codes[good_codes >= 10]\n",
    "\n",
    "mcc_info = transactions[transactions.mcc_code.isin(good_codes)].pivot_table(\n",
    "    index = 'user_id',\n",
    "    values=['transaction_amt'],\n",
    "    columns=['mcc_code'],\n",
    "    aggfunc=['count', 'median', 'sum']\n",
    ").fillna(0)\n",
    "mcc_info.columns = ['main_' + '_'.join(map(str, x)) for x in mcc_info.columns]\n",
    "\n",
    "count_cols = [x for x in mcc_info.columns if 'count' in x]\n",
    "mcc_info['sum'] = mcc_info[count_cols].sum(axis=1)\n",
    "for col in count_cols:\n",
    "    mcc_info[f'{col}_norm'] = mcc_info[col] / mcc_info['sum']\n",
    "mcc_info.drop('sum', axis=1, inplace=True)\n",
    "\n",
    "main = main.merge(mcc_info, how='left', left_on='user_id', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_more = transactions.merge(clients[['user_id', 'report']], how='left', on='user_id')\n",
    "df_more = df_more.merge(report_dates, how='left', on='report')\n",
    "df_more['days_to_report'] = (df_more['report_dt'] - df_more['transaction_dttm']).dt.days\n",
    "\n",
    "\n",
    "for day_diff in [30, 1000]:\n",
    "\n",
    "    # Информация о размерах транзакций в различных валютах\n",
    "    currency_pivot = df_more[df_more['days_to_report'] < day_diff + 100].pivot_table(\n",
    "        index='user_id',\n",
    "        columns='currency_rk',\n",
    "        values='transaction_amt',\n",
    "        aggfunc=['sum', 'mean', 'median', 'count']\n",
    "    ).fillna(0)\n",
    "    currency_pivot.columns = [f'currency_daydiff_{day_diff}_{x[0]}_{x[1]}' for x in currency_pivot.columns]\n",
    "\n",
    "    currency_pivot['sum'] = currency_pivot[[x for x in currency_pivot.columns if 'count' in x]].sum(axis=1)\n",
    "    for x in range(4):\n",
    "        currency_pivot[f'currency_daydiff_{day_diff}_count_{x}_norm'] = currency_pivot[f'currency_daydiff_{day_diff}_count_{x}'] / currency_pivot['sum']\n",
    "    currency_pivot.drop('sum', axis=1, inplace=True)\n",
    "\n",
    "    main = main.merge(currency_pivot, how='left', left_on='user_id', right_index=True)\n",
    "\n",
    "\n",
    "    general_trans_info = df_more[df_more['days_to_report'] < day_diff + 100].groupby('user_id')['transaction_amt'].agg(['sum', 'count', 'median'])\n",
    "    general_trans_info[['sum', 'count']] = general_trans_info[['sum', 'count']].fillna(0)\n",
    "    general_trans_info.columns = [f'general_trans_info_{day_diff}_{x}' for x in general_trans_info]\n",
    "    main = main.merge(general_trans_info, how='left', left_on='user_id', right_index=True)\n",
    "\n",
    "    general_trans_info = df_more[(df_more['days_to_report']<day_diff + 100)&(df_more['transaction_amt']>0)].groupby('user_id')['transaction_amt'].agg(['sum', 'count', 'median'])\n",
    "    general_trans_info[['sum', 'count']] = general_trans_info[['sum', 'count']].fillna(0)\n",
    "    general_trans_info.columns = [f'positive_general_trans_info_{day_diff}_{x}' for x in general_trans_info]\n",
    "    main = main.merge(general_trans_info, how='left', left_on='user_id', right_index=True)\n",
    "\n",
    "    general_trans_info = df_more[(df_more['days_to_report']<day_diff + 100)&(df_more['transaction_amt']<0)].groupby('user_id')['transaction_amt'].agg(['sum', 'count', 'median'])\n",
    "    general_trans_info[['sum', 'count']] = general_trans_info[['sum', 'count']].fillna(0)\n",
    "    general_trans_info.columns = [f'negative_general_trans_info_{day_diff}_{x}' for x in general_trans_info]\n",
    "    main = main.merge(general_trans_info, how='left', left_on='user_id', right_index=True)\n",
    "\n",
    "\n",
    "# Анализируем кол-во транзакций в последние n дней / кол-во транзакций до последних n дней\n",
    "for x in [5, 30]:\n",
    "    prev = df_more[df_more['days_to_report'] > x + 100].groupby('user_id')['report'].agg(['count']).reset_index().rename({'count': f'num_transaction_before_{x}_days'}, axis=1)\n",
    "    last = df_more[df_more['days_to_report'] <= x + 100].groupby('user_id')['report'].agg(['count']).reset_index().rename({'count': f'num_transaction_last_{x}_days'}, axis=1)\n",
    "\n",
    "    main = main.merge(prev, how='left', on='user_id')\n",
    "    main = main.merge(last, how='left', on='user_id')\n",
    "    main[f'num_transaction_last_{x}_days'].fillna(0, inplace=True)\n",
    "    main[f'num_transaction_before_{x}_days'].fillna(0, inplace=True)\n",
    "    main[f'percent_last_{x}'] = main[f'num_transaction_last_{x}_days'] / main[f'num_transaction_before_{x}_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кол-во уникальных MCC кодов, валют, а также уникальных дней, в которые были транзакции\n",
    "main = main.merge(df_more.groupby('user_id')['days_to_report'].nunique(), how='left', on='user_id').rename({'days_to_report': 'nunique_days'}, axis=1)\n",
    "main = main.merge(df_more.groupby('user_id')['mcc_code'].nunique(), how='left', on='user_id').rename({'mcc_code': 'nunique_mcc_codes'}, axis=1)\n",
    "main = main.merge(df_more.groupby('user_id')['currency_rk'].nunique(), how='left', on='user_id').rename({'currency_rk': 'nunique_currency'}, axis=1)\n",
    "\n",
    "main = main.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = transactions.copy()\n",
    "tmp['hour'] = tmp['transaction_dttm'].dt.hour\n",
    "pivot_table = tmp.pivot_table(\n",
    "    index='user_id',\n",
    "    columns='hour',\n",
    "    values='transaction_amt',\n",
    "    aggfunc=['count', 'median']\n",
    ").fillna(0)\n",
    "pivot_table.columns = [f'hour_{x[0]}_{x[1]}' for x in pivot_table.columns]\n",
    "\n",
    "count_cols = [x for x in pivot_table.columns if 'count' in x]\n",
    "pivot_table['sum'] = pivot_table[count_cols].sum(axis=1)\n",
    "for col in count_cols:\n",
    "    pivot_table[f'{col}_norm'] = pivot_table[col] / pivot_table['sum']\n",
    "pivot_table.drop('sum', axis=1, inplace=True)\n",
    "\n",
    "main = main.merge(pivot_table, how='left', left_on='user_id', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = transactions.groupby('user_id')['transaction_dttm'].agg(['min', 'max']).reset_index()\n",
    "cur = cur.merge(clients[['user_id', 'report']], how='left', on='user_id')\n",
    "cur = cur.merge(report_dates, how='left', on='report')\n",
    "\n",
    "cur['min_diff_dttm'] = (cur['report_dt'] - cur['min']).dt.days\n",
    "cur['days_to_report'] = (cur['report_dt'] - cur['max']).dt.days\n",
    "cur['max_min_diff_dttm'] = cur['days_to_report'] - cur['min_diff_dttm']\n",
    "\n",
    "main = main.merge(cur[['user_id', 'min_diff_dttm','days_to_report','max_min_diff_dttm']], how='left', on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main['trx_density'] = main['max_min_diff_dttm'] / main['general_trans_info_1000_count']\n",
    "main['days_density'] = (main['max_min_diff_dttm'] + 1) / main['nunique_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['customer_age', 'employee_count_nm', 'report']\n",
    "main[cat_cols] = main[cat_cols].astype(str)\n",
    "main = main.fillna(0)\n",
    "main = main.sort_values('user_id').reset_index(drop=True)\n",
    "train = main[main.target != -1]\n",
    "test = main[main.target == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = pd.read_csv('../data/test_ids.csv')\n",
    "train_, test_ = train.loc[~train['user_id'].isin(test_ids['user_id'])], train.loc[train['user_id'].isin(test_ids['user_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    iterations = 1400,\n",
    "    depth=4,\n",
    "    learning_rate=0.03,\n",
    "    task_type=\"GPU\",\n",
    "    eval_metric='AUC',\n",
    "    cat_features = cat_cols,\n",
    "    thread_count=6,\n",
    "    l2_leaf_reg=5,\n",
    "    early_stopping_rounds=200,\n",
    ")\n",
    "model.fit(train_.drop(['user_id', 'target', 'time'], axis=1), train_['target'], verbose=100)\n",
    "\n",
    "\n",
    "df_imp = pd.DataFrame({\n",
    "    'name': train_.drop(['user_id', 'target', 'time'], axis=1).columns,\n",
    "    'imp': model.get_feature_importance()\n",
    "}).sort_values('imp', ascending=False)\n",
    "\n",
    "df_imp = df_imp[df_imp['imp'] > 0.15]\n",
    "good_cols = df_imp['name'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучаемся на train_ выборке с сидом 42, получаем предикты для стекинга и отложенной выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "strat_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "X, y = train_.drop(['time', 'target'], axis=1), train_['target']\n",
    "scores = []\n",
    "frames_for_metamodel = []\n",
    "models = []\n",
    "for train_index, valid_index in strat_kfold.split(train_, train_['target']):\n",
    "    \n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[valid_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[valid_index]\n",
    "    \n",
    "    model = CatBoostClassifier(\n",
    "        iterations = 5000,\n",
    "        depth=4,\n",
    "        learning_rate=0.03,\n",
    "        eval_metric='AUC',\n",
    "        task_type=\"GPU\",\n",
    "        cat_features = cat_cols,\n",
    "        early_stopping_rounds=400,\n",
    "        random_seed=42,\n",
    "    )\n",
    "\n",
    "    model.fit(Pool(X_train[good_cols], y_train, cat_features=cat_cols),\n",
    "              eval_set=Pool(X_val[good_cols], y_val, cat_features=cat_cols),\n",
    "              verbose=100)\n",
    "    models.append(model)\n",
    "    \n",
    "    pred = model.predict_proba(X_val[good_cols])[:, 1]\n",
    "    frames_for_metamodel.append(pd.DataFrame({'user_id': X_val.user_id.values, 'pred_agg': pred}))\n",
    "    scores.append(metrics.roc_auc_score(y_val, pred))\n",
    "\n",
    "print(np.mean(scores))\n",
    "metadata = pd.concat(frames_for_metamodel, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict = np.zeros(len(test_))\n",
    "for i in range(len(models)):\n",
    "    predict += models[i].predict_proba(test_[good_cols])[:, 1]\n",
    "test_pred = {'user_id': test_.user_id.values, 'pred_agg': predict}\n",
    "test_pred = pd.DataFrame(test_pred)\n",
    "test_pred['pred_agg'] = test_pred['pred_agg']/5\n",
    "print(metrics.roc_auc_score(test_['target'], predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучаемся на всей выборке, получаем финальные предикты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "strat_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "X, y = train.drop(['time', 'target'], axis=1), train['target']\n",
    "scores = []\n",
    "\n",
    "models = []\n",
    "for train_index, valid_index in strat_kfold.split(train, train['target']):\n",
    "    \n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[valid_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[valid_index]\n",
    "    \n",
    "    model = CatBoostClassifier(\n",
    "        iterations = 5000,\n",
    "        depth=4,\n",
    "        learning_rate=0.03,\n",
    "        eval_metric='AUC',\n",
    "        task_type=\"GPU\",\n",
    "        cat_features = cat_cols,\n",
    "        early_stopping_rounds=400,\n",
    "        random_seed=42,\n",
    "    )\n",
    "\n",
    "    model.fit(Pool(X_train[good_cols], y_train, cat_features=cat_cols),\n",
    "              eval_set=Pool(X_val[good_cols], y_val, cat_features=cat_cols),\n",
    "              verbose=100)\n",
    "    models.append(model)\n",
    "    \n",
    "    pred = model.predict_proba(X_val[good_cols])[:, 1]\n",
    "    scores.append(metrics.roc_auc_score(y_val, pred))\n",
    "\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = np.zeros(len(test))\n",
    "for i in range(len(models)):\n",
    "    predict += models[i].predict_proba(test[good_cols])[:, 1]\n",
    "real_pred = {'user_id': test.user_id.values, 'pred_agg': predict}\n",
    "real_pred = pd.DataFrame(real_pred)\n",
    "real_pred['pred_agg'] = real_pred['pred_agg']/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.concat([metadata, test_pred, real_pred])\n",
    "metadata.to_csv('../predictions/agg_kdimon15_pred_meta.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datafusion",
   "language": "python",
   "name": "datafusion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
